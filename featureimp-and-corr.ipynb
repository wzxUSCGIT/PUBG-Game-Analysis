{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train_V2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87f837b357a99a1b520d886efdf326062d4e55af"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10b128633c4b630ebdc1a42b07f9d44a38a92c36"},"cell_type":"markdown","source":"**Feature importance**"},{"metadata":{"trusted":true,"_uuid":"072dc92cbc5a4cb16a7ef74b4dd9c885e2a5ceee"},"cell_type":"code","source":"print('Match types in the dataset: {}'.format(train['matchType'].nunique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"716e7ce7e52f097555ace632c354b1da55e0f4e8"},"cell_type":"code","source":"# One-hot encode matchType\ntrain = pd.get_dummies(train, columns=['matchType'])\nmatchType_onehot = train.filter(regex='matchType')\nmatchType_onehot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97b09a352f7355d46b5eebfa756ac297cc6f0b93"},"cell_type":"code","source":"# Change data type of groupId and match Id\ntrain['groupId'] = train['groupId'].astype('category')\ntrain['groupId_c'] = train['groupId'].cat.codes\ntrain['matchId'] = train['matchId'].astype('category')\ntrain['matchId_c'] = train['matchId'].cat.codes\ntrain.drop(columns=['groupId', 'matchId'], inplace=True)\ntrain[['groupId_c', 'matchId_c']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80b1fe723740905a92fd63ab188cdc922c86af86"},"cell_type":"code","source":"# Drop Id variable and take sample\ntrain.drop(columns = ['Id'], inplace=True)\nsample = 500000\ndf_sample = train.sample(sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6422f0109b2331478333a4ec62af81518550de0c"},"cell_type":"code","source":"# Split sample into training data and target variable\ndf = df_sample.drop(columns = ['winPlacePerc']) #all columns except target\ny = df_sample['winPlacePerc'] # Only target variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61dd4446a6ac726d4532f1392d6611d2713cae40"},"cell_type":"code","source":"# Function for splitting training and validation data\ndef split_vals(a, n : int): \n    return a[:n].copy(), a[n:].copy()\nperc_valid = 0.12\nn_valid = int(perc_valid * sample) \nn_trn = len(df)-n_valid\n# Split data\nraw_train, raw_valid = split_vals(df_sample, n_trn)\nX_train, X_valid = split_vals(df, n_trn)\ny_train, y_valid = split_vals(y, n_trn)\n\nprint('Sample train shape: ', X_train.shape, \n      'Sample target shape: ', y_train.shape, \n      'Sample validation shape: ', X_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbe9736aa7ea9afd66bcd348a7df26c4e24b32b4"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Function to print the MAE (Mean Absolute Error) score\ndef print_score(m : RandomForestRegressor):\n    res = ['mae train: ', mean_absolute_error(m.predict(X_train), y_train), \n           'mae val: ', mean_absolute_error(m.predict(X_valid), y_valid)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01d84c40824b0c0469908585fd80cca2fcc9f2b5"},"cell_type":"code","source":"# Basic model\nmodel_1 = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features='sqrt', n_jobs=-1)\nmodel_1.fit(X_train, y_train)\nprint_score(model_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8f8637eb9f8bd0330eacc00737f66f3801cc30c"},"cell_type":"code","source":"# Find the most important features according to our basic model\nfrom fastai.imports import *\nfrom fastai.structured import *\nfi = rf_feat_importance(model_1, df); fi[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45be64f3c7f3f7ba985f61c5c614ac6dc315f556"},"cell_type":"code","source":"# Plot a feature importance graph for the 20 most important features\nplot_1 = fi[:20].plot('cols', 'imp', figsize=(14,6), legend=False, kind='barh', color='#2976bb')\nplot_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"b2739af16ebc709dc42465a8f8982e937b530cde"},"cell_type":"code","source":"# Keep only significant features\nto_keep = fi[fi.imp>0.005].cols\nprint('Significant features: ', len(to_keep))\nto_keep","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf8a1fc2985475d5bb91cb7fe590fdbf14bff566"},"cell_type":"code","source":"# Make a DataFrame with only significant features\ndata_keep = df[to_keep].copy()\nX_train, X_valid = split_vals(data_keep, n_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7cdc63e2eae05f38309a79fcca2b00d377ef320"},"cell_type":"code","source":"# Train model on top features\nmodel_2 = RandomForestRegressor(n_estimators=80, min_samples_leaf=3, max_features='sqrt', n_jobs=-1)\nmodel_2.fit(X_train, y_train)\nprint_score(model_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a8028971ab9bda9a8aac4535ef96e90ce4b9f74"},"cell_type":"code","source":"# Get feature importances of our top features\nfi_to_keep = rf_feat_importance(model_2, data_keep)\nplot_2 = fi_to_keep.plot('cols', 'imp', figsize=(14,6), legend=False, kind='barh', color='#2976bb')\nplot_2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74b491aafd4bad56d224926330c7cbbfe052c044"},"cell_type":"markdown","source":"**Correlations**"},{"metadata":{"trusted":true,"_uuid":"d1a1aef04c22bf9e452ed3fdaac3616a76c60370","scrolled":true},"cell_type":"code","source":"from scipy.cluster import hierarchy as hc\n\n# Create a Dendrogram to view highly correlated features\ncorr = np.round(scipy.stats.spearmanr(data_keep).correlation, 4)\ncorr_condensed = hc.distance.squareform(1-corr)\nz = hc.linkage(corr_condensed, method='average')\nfig = plt.figure(figsize=(14,10))\ndendrogram = hc.dendrogram(z, labels=data_keep.columns, orientation='left', leaf_font_size=16)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"352c38ee339283873e23e44468da80ec91c95d92"},"cell_type":"code","source":"# Correlation heatmap\ncorr = data_keep.corr()\nf, ax = plt.subplots(figsize=(11, 9))\nheatmap = sns.heatmap(corr, annot=True, linewidths=.5, fmt= '.1f', cmap=\"YlGnBu\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}